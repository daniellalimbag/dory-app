{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ea27826",
   "metadata": {},
   "source": [
    "Test for stroke count and stroke rate\n",
    "\n",
    "1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b06e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605c55f72185490f85142d39b3ea98aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='DB file path:', layout=Layout(width='80%'), placeholder='C:/path/to/your/database.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e9134457ec4609865a3152e2fdc302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Load DB', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea2fbc93007d498283df97be8a89c194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f01b9f0bc4324ae4bd6e7f87e0e29e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='CSV file path:', layout=Layout(width='80%'), placeholder='C:/path/to/your/stroke_d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13775c9f692a4025b0bb676b80344679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Load CSV', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f7a9ffc40e4e3bbba05bc232b8ef17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks, butter, filtfilt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from pathlib import Path\n",
    "\n",
    "if 'df' not in globals():\n",
    "    df = pd.DataFrame()\n",
    "if 'csv_df' not in globals():\n",
    "    csv_df = pd.DataFrame()\n",
    "\n",
    "db_file_input = widgets.Text(\n",
    "    value=\"\",\n",
    "    placeholder=\"C:/path/to/your/database.db\",\n",
    "    description='DB file path:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "load_db_button = widgets.Button(description=\"Load DB\", button_style='primary')\n",
    "db_load_output = widgets.Output()\n",
    "\n",
    "csv_file_input = widgets.Text(\n",
    "    value=\"\",\n",
    "    placeholder=\"C:/path/to/your/stroke_data.csv\",\n",
    "    description='CSV file path:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "load_csv_button = widgets.Button(description=\"Load CSV\", button_style='info')\n",
    "csv_load_output = widgets.Output()\n",
    "\n",
    "\n",
    "def load_db(_):\n",
    "    with db_load_output:\n",
    "        clear_output()\n",
    "        db_path = Path(db_file_input.value)\n",
    "        if not db_path.exists():\n",
    "            print(f\"Path not found: {db_path}\")\n",
    "            return\n",
    "        try:\n",
    "            conn = sqlite3.connect(str(db_path))\n",
    "            print(\"Available tables:\")\n",
    "            tables = pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
    "            display(tables)\n",
    "\n",
    "            table_name = 'sensor_data'\n",
    "            if table_name in tables['name'].values:\n",
    "                global df\n",
    "                df = pd.read_sql(f\"SELECT * FROM {table_name};\", conn)\n",
    "\n",
    "                # UNIX to ISO\n",
    "                if \"unix_ts\" in df.columns:\n",
    "                    df['datetime'] = (\n",
    "                        pd.to_datetime(df['unix_ts'], unit='ms', utc=True)\n",
    "                          .dt.tz_convert('Asia/Manila')\n",
    "                    )\n",
    "                elif \"timestamp\" in df.columns:\n",
    "                    df['datetime'] = (\n",
    "                        pd.to_datetime(df['timestamp'], unit='ms', utc=True)\n",
    "                          .dt.tz_convert('Asia/Manila')\n",
    "                    )\n",
    "                else:\n",
    "                    print(f\"Neither 'unix_ts' nor 'timestamp' column found in '{table_name}'. Cannot create 'datetime' column.\")\n",
    "                    return\n",
    "\n",
    "                print(f\"\\nPreview of '{table_name}':\")\n",
    "                display(df.head(5))\n",
    "\n",
    "                print(\"Columns:\")\n",
    "                print(df.columns.tolist())\n",
    "\n",
    "                if 'datetime' in df.columns:\n",
    "                    print(\"\\nTime range in dataset (Asia/Manila):\")\n",
    "                    print(df['datetime'].min(), \"to\", df['datetime'].max())\n",
    "            else:\n",
    "                print(f\"Table '{table_name}' not found in database.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to open DB: {e}\")\n",
    "\n",
    "\n",
    "load_db_button.on_click(load_db)\n",
    "\n",
    "\n",
    "def load_csv(_):\n",
    "    with csv_load_output:\n",
    "        clear_output()\n",
    "        csv_path = Path(csv_file_input.value)\n",
    "        if not csv_path.exists():\n",
    "            print(f\"Path not found: {csv_path}\")\n",
    "            return\n",
    "        try:\n",
    "            global csv_df\n",
    "            csv_df = pd.read_csv(csv_path)\n",
    "\n",
    "            # Create datetime from available timestamp column\n",
    "            if \"unix_ts\" in csv_df.columns:\n",
    "                csv_df['datetime'] = (\n",
    "                    pd.to_datetime(csv_df['unix_ts'], unit='ms', utc=True)\n",
    "                      .dt.tz_convert('Asia/Manila')\n",
    "                )\n",
    "            elif \"timestamp\" in csv_df.columns:\n",
    "                csv_df['datetime'] = (\n",
    "                    pd.to_datetime(csv_df['timestamp'], unit='ms', utc=True)\n",
    "                      .dt.tz_convert('Asia/Manila')\n",
    "                )\n",
    "\n",
    "            print(f\"\\nPreview of '{csv_path.name}':\")\n",
    "            display(csv_df.head(30))\n",
    "\n",
    "            print(\"Columns:\")\n",
    "            print(csv_df.columns.tolist())\n",
    "\n",
    "            if 'datetime' in csv_df.columns:\n",
    "                print(\"\\nTime range in CSV dataset (Asia/Manila):\")\n",
    "                print(csv_df['datetime'].min(), \"to\", csv_df['datetime'].max())\n",
    "            else:\n",
    "                print(\"Warning: CSV has no 'unix_ts' or 'timestamp' column, so 'datetime' could not be created.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load CSV: {e}\")\n",
    "\n",
    "\n",
    "load_csv_button.on_click(load_csv)\n",
    "\n",
    "\n",
    "display(db_file_input, load_db_button, db_load_output,\n",
    "        csv_file_input, load_csv_button, csv_load_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d61b9a",
   "metadata": {},
   "source": [
    "2. Butterworth filter\n",
    "\n",
    "References:\n",
    "https://doi.org/10.1016/j.proeng.2010.04.055\n",
    "\n",
    "http://dx.doi.org/10.4236/jsip.2012.34062"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec58bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass_filter(data, lowcut=0.25, highcut=0.5, fs=50, order=2):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return filtfilt(b, a, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a80512",
   "metadata": {},
   "source": [
    "3. Sampling rate estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dc852dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_sampling_rate(df):\n",
    "    diffs = df['datetime'].diff().dt.total_seconds().dropna()\n",
    "    return 1.0 / diffs.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb9d917",
   "metadata": {},
   "source": [
    "4. Stroke cycle identification (Peak detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e645fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_stroke_cycles(segment):\n",
    "    if not all(col in segment.columns for col in ['accel_y', 'accel_z']):\n",
    "        print(\"accel_y and accel_z not found.\")\n",
    "        return 0, [], []\n",
    "\n",
    "    fs = estimate_sampling_rate(segment)\n",
    "    ay_f = butter_bandpass_filter(segment['accel_y'].values, fs=fs)\n",
    "    az_f = butter_bandpass_filter(segment['accel_z'].values, fs=fs)\n",
    "    signal = ay_f + az_f\n",
    "\n",
    "    peaks, _ = find_peaks(signal)\n",
    "    valid_peaks = list(peaks)\n",
    "\n",
    "    return len(valid_peaks), valid_peaks, signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd0d6bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_strokes_butterfly(segment):\n",
    "    \"\"\"Butterfly-specific stroke detection using gyro magnitude.\n",
    "\n",
    "    Separate from the default accel-based pipeline and only used\n",
    "    when explicitly selected in the evaluation widgets.\n",
    "    \"\"\"\n",
    "    required_cols = ['gyro_x', 'gyro_y', 'gyro_z']\n",
    "    if not all(col in segment.columns for col in required_cols):\n",
    "        print(\"Butterfly detection: gyro_x/gyro_y/gyro_z not found.\")\n",
    "        return 0, [], []\n",
    "\n",
    "    fs = estimate_sampling_rate(segment)\n",
    "\n",
    "    gx = segment['gyro_x'].values\n",
    "    gy = segment['gyro_y'].values\n",
    "    gz = segment['gyro_z'].values\n",
    "    gyro_mag = np.sqrt(gx**2 + gy**2 + gz**2)\n",
    "\n",
    "    # Smooth gyro magnitude (~0.3 s moving average)\n",
    "    window = max(1, int(fs * 0.3))\n",
    "    gyro_series = pd.Series(gyro_mag)\n",
    "    gyro_smooth = gyro_series.rolling(window, center=True, min_periods=1).mean().values\n",
    "\n",
    "    # Peak detection tuned for ~22–30 spm butterfly\n",
    "    # Allow a bit shorter minimum interval and lower prominence than before\n",
    "    min_interval_s = 1.2  # ~1.2 s between peaks; prevents double-counting but less aggressive\n",
    "    distance = max(1, int(fs * min_interval_s))\n",
    "\n",
    "    scale = np.std(gyro_smooth)\n",
    "    prominence = max(5.0, 1.2 * scale)  # reduced so we don't miss real strokes\n",
    "\n",
    "    peaks, _ = find_peaks(\n",
    "        gyro_smooth,\n",
    "        distance=distance,\n",
    "        prominence=prominence\n",
    "    )\n",
    "\n",
    "    stroke_count = len(peaks)\n",
    "    return stroke_count, list(peaks), gyro_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaa3db4",
   "metadata": {},
   "source": [
    "5. Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ba23b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97aeb6b42a174465a06449d3e76ae7b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Data Source:', options=(('Database (Accelerometer)', 'db'), ('CSV (Annotated Strokes)', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce8e65b056d433fb2f51917d79ce113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='07:00:00', description='Start Time (HH:MM:SS GMT+8):', layout=Layout(width='90%'), style=TextStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92758892d119433987ae82fcd3ec2547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='07:05:00', description='End Time (HH:MM:SS GMT+8):', layout=Layout(width='90%'), style=TextStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31fb6f629f924805bcd20e6c73c86075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Calculate Stroke Metrics', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bccf0052940846a8968f4d8590f3f100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# inputs\n",
    "data_source_select = widgets.Dropdown(\n",
    "    options=[('Database (Accelerometer)', 'db'), ('CSV (Annotated Strokes)', 'csv')],\n",
    "    value='db',\n",
    "    description='Data Source:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "start_time_input = widgets.Text(\n",
    "    value=\"07:00:00\",\n",
    "    description='Start Time (HH:MM:SS GMT+8):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "end_time_input = widgets.Text(\n",
    "    value=\"07:05:00\",\n",
    "    description='End Time (HH:MM:SS GMT+8):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def calculate_stroke_metrics(change):\n",
    "    with output:\n",
    "        clear_output()\n",
    "\n",
    "        source = data_source_select.value\n",
    "        current_df = None\n",
    "        if source == 'db':\n",
    "            if 'df' not in globals() or df.empty:\n",
    "                print(\"DB data not loaded. Please load the .db file first.\")\n",
    "                return\n",
    "            current_df = df\n",
    "        elif source == 'csv':\n",
    "            if 'csv_df' not in globals() or csv_df.empty:\n",
    "                print(\"CSV data not loaded. Please load the .csv file first.\")\n",
    "                return\n",
    "            current_df = csv_df\n",
    "        \n",
    "        if 'datetime' not in current_df.columns:\n",
    "            print(\"Error: 'datetime' column not found in the selected data. Please ensure the data is loaded correctly with a 'timestamp' or 'unix_ts' column.\")\n",
    "            return\n",
    "        \n",
    "        if current_df['datetime'].empty:\n",
    "            print(\"Error: 'datetime' column is empty. No time data available for analysis.\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\nFull data time range (GMT+8): {current_df['datetime'].min().strftime('%Y-%m-%d %H:%M:%S')} to {current_df['datetime'].max().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "        try:\n",
    "            start_time_str = start_time_input.value\n",
    "            end_time_str = end_time_input.value\n",
    "\n",
    "            base_date = current_df['datetime'].iloc[0].date()\n",
    "            \n",
    "            start_time = pd.to_datetime(f\"{base_date} {start_time_str}\").tz_localize('Asia/Manila')\n",
    "            end_time = pd.to_datetime(f\"{base_date} {end_time_str}\").tz_localize('Asia/Manila')\n",
    "\n",
    "            print(f\"Filtering for: {start_time.strftime('%Y-%m-%d %H:%M:%S')} GMT+8 to {end_time.strftime('%Y-%m-%d %H:%M:%S')} GMT+8\")\n",
    "\n",
    "        except ValueError:\n",
    "            print(\"Invalid time format. Please use HH:MM:SS.\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing times: {e}\")\n",
    "            return\n",
    "\n",
    "        mask = (current_df['datetime'] >= start_time) & (current_df['datetime'] <= end_time)\n",
    "        segment = current_df[mask]\n",
    "\n",
    "        if segment.empty:\n",
    "            print(\"No data in selected time range.\")\n",
    "            return\n",
    "\n",
    "        if source == 'db':\n",
    "            # stroke cycle identification for DB data\n",
    "            stroke_count, peaks, signal = identify_stroke_cycles(segment)\n",
    "            print(f\"Detected Stroke Count (DB): {stroke_count}\")\n",
    "\n",
    "            # calculate stroke rate\n",
    "            duration_seconds = (end_time - start_time).total_seconds()\n",
    "            stroke_rate = (stroke_count / duration_seconds) * 60 if duration_seconds > 0 else 0\n",
    "            print(f\"Stroke Rate (DB): {stroke_rate:.2f} strokes/min\")\n",
    "\n",
    "            # results plot\n",
    "            plt.figure(figsize=(12,4))\n",
    "            plt.plot(segment['datetime'], signal, label=\"Filtered ay+az\")\n",
    "            if len(peaks) > 0:\n",
    "                plt.plot(segment['datetime'].iloc[peaks], signal[peaks], \"rx\", label=\"Strokes\")\n",
    "            plt.xlabel(\"Time\")\n",
    "            plt.ylabel(\"Filtered Acceleration (m/s^2)\")\n",
    "            plt.legend()\n",
    "            plt.title(f\"Stroke Analysis (DB Data) from {start_time.strftime('%H:%M:%S')} to {end_time.strftime('%H:%M:%S')}\")\n",
    "            plt.show()\n",
    "        elif source == 'csv':\n",
    "            # stroke count\n",
    "            stroke_count = segment.shape[0]\n",
    "            print(f\"Annotated Stroke Count (CSV): {stroke_count}\")\n",
    "\n",
    "            # calculate stroke rate\n",
    "            duration_seconds = (end_time - start_time).total_seconds()\n",
    "            stroke_rate = (stroke_count / duration_seconds) * 60 if duration_seconds > 0 else 0\n",
    "            print(f\"Stroke Rate (CSV): {stroke_rate:.2f} strokes/min\")\n",
    "\n",
    "calc_button = widgets.Button(\n",
    "    description=\"Calculate Stroke Metrics\",\n",
    "    button_style='success'\n",
    ")\n",
    "\n",
    "calc_button.on_click(None)\n",
    "calc_button.on_click(calculate_stroke_metrics)\n",
    "\n",
    "display(data_source_select, start_time_input, end_time_input, calc_button, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b828a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89abfef90d8244079130de8be1fac193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='warning', description='Compare Data', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a7147744ea414088aac79bb9ccb64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_all_button = widgets.Button(\n",
    "    description=\"Compare Data\",\n",
    "    button_style='warning'\n",
    ")\n",
    "compare_output = widgets.Output()\n",
    "\n",
    "\n",
    "def compare_all_data(_):\n",
    "    with compare_output:\n",
    "        clear_output()\n",
    "\n",
    "        # Basic checks\n",
    "        if 'csv_df' not in globals() or csv_df.empty:\n",
    "            print(\"CSV data not loaded. Please load the .csv file first.\")\n",
    "            return\n",
    "        if 'df' not in globals() or df.empty:\n",
    "            print(\"DB data not loaded. Please load the .db file first.\")\n",
    "            return\n",
    "        if 'datetime' not in csv_df.columns or 'datetime' not in df.columns:\n",
    "            print(\"Error: 'datetime' column not found in one or both data sources.\")\n",
    "            return\n",
    "\n",
    "        # Determine common time range based on CSV timestamps\n",
    "        if 'unix_ts' in csv_df.columns:\n",
    "            start_unix = csv_df['unix_ts'].iloc[0]\n",
    "            end_unix = csv_df['unix_ts'].iloc[-1]\n",
    "            start_dt = pd.to_datetime(start_unix, unit='ms', utc=True).tz_convert('Asia/Manila')\n",
    "            end_dt = pd.to_datetime(end_unix, unit='ms', utc=True).tz_convert('Asia/Manila')\n",
    "        elif 'timestamp' in csv_df.columns:\n",
    "            start_unix = csv_df['timestamp'].iloc[0]\n",
    "            end_unix = csv_df['timestamp'].iloc[-1]\n",
    "            start_dt = pd.to_datetime(start_unix, unit='ms', utc=True).tz_convert('Asia/Manila')\n",
    "            end_dt = pd.to_datetime(end_unix, unit='ms', utc=True).tz_convert('Asia/Manila')\n",
    "        else:\n",
    "            print(\"CSV does not have 'unix_ts' or 'timestamp' column.\")\n",
    "            return\n",
    "\n",
    "        print(f\"Comparing over time range: {start_dt} to {end_dt}\")\n",
    "\n",
    "        # Ground‑truth strokes from CSV (one row = one annotated stroke)\n",
    "        csv_stroke_count = csv_df.shape[0]\n",
    "        print(f\"\\nAnnotated Stroke Count (CSV): {csv_stroke_count}\")\n",
    "\n",
    "        # Detected strokes from DB over the same time window\n",
    "        db_segment = df[(df['datetime'] >= start_dt) & (df['datetime'] <= end_dt)]\n",
    "        if db_segment.empty:\n",
    "            print(\"No DB data in this time range.\")\n",
    "            db_stroke_count = 0\n",
    "        else:\n",
    "            db_stroke_count, _, _ = identify_stroke_cycles(db_segment)\n",
    "        print(f\"Detected Stroke Count (peak detection, DB): {db_stroke_count}\")\n",
    "\n",
    "        # Simple accuracy metrics based on counts\n",
    "        if csv_stroke_count > 0:\n",
    "            count_error = db_stroke_count - csv_stroke_count\n",
    "            abs_error = abs(count_error)\n",
    "            percent_error = (abs_error / csv_stroke_count) * 100.0\n",
    "            count_accuracy = max(0.0, 1.0 - (abs_error / csv_stroke_count)) * 100.0\n",
    "\n",
    "            print(\"\\nAccuracy summary (count‑based):\")\n",
    "            print(f\"  Count error (DB - CSV): {count_error}\")\n",
    "            print(f\"  Absolute error: {abs_error}\")\n",
    "            print(f\"  Percent error: {percent_error:.2f}%\")\n",
    "            print(f\"  Count accuracy: {count_accuracy:.2f}%\")\n",
    "        else:\n",
    "            print(\"\\nCSV annotated stroke count is zero; cannot compute percentage accuracy.\")\n",
    "\n",
    "\n",
    "compare_all_button.on_click(compare_all_data)\n",
    "\n",
    "display(compare_all_button, compare_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac177b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23853219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e026b7e3da5d4800965dbf0df88a0be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Stroke Count Accuracy Evaluation</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154db2c64450499db9090be6b835da93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Detection source:', options=(('Database (Accelerometer)', 'db'),), style=DescriptionStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc79a53def98499090a2b59b21c0b8fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Stroke type:', options=('Freestyle', 'Backstroke', 'Breaststroke', 'Butterfly'), style=D…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47385cd63d674d4eb800bdc0b4e690cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Range:', options=(('Whole dataset', 'whole'), ('Time window (GMT+8)', 'window')), style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0fd972562d54589be01051eb9248496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='Start (YYYY-MM-DD HH:MM:SS):', layout=Layout(display='none', width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb4a74ed36a4b8d80369080c1aeb9ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=0, description='Actual stroke count:', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2652dc0b60f243d7b856a7218c09ae78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Evaluate Accuracy', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "176b6699c3324511872d513e6d7939e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stroke Count Accuracy Evaluation\n",
    "\n",
    "accuracy_source_select = widgets.Dropdown(\n",
    "    options=[('Database (Accelerometer)', 'db')],\n",
    "    value='db',\n",
    "    description='Detection source:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "stroke_type_select = widgets.Dropdown(\n",
    "    options=['Freestyle', 'Backstroke', 'Breaststroke', 'Butterfly'],\n",
    "    value='Freestyle',\n",
    "    description='Stroke type:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "range_mode_select = widgets.Dropdown(\n",
    "    options=[('Whole dataset', 'whole'), ('Time window (GMT+8)', 'window')],\n",
    "    value='whole',\n",
    "    description='Range:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "acc_start_input = widgets.Text(\n",
    "    value=\"\",  # e.g. \"2025-05-20 07:19:30\"\n",
    "    description='Start (YYYY-MM-DD HH:MM:SS):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='95%')\n",
    ")\n",
    "\n",
    "acc_end_input = widgets.Text(\n",
    "    value=\"\",\n",
    "    description='End   (YYYY-MM-DD HH:MM:SS):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='95%')\n",
    ")\n",
    "\n",
    "actual_strokes_input = widgets.IntText(\n",
    "    value=0,\n",
    "    description='Actual stroke count:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "eval_button = widgets.Button(\n",
    "    description='Evaluate Accuracy',\n",
    "    button_style='success'\n",
    ")\n",
    "\n",
    "eval_output = widgets.Output()\n",
    "\n",
    "\n",
    "def _get_eval_segment():\n",
    "    \"\"\"Return (segment_df, message) for the chosen range mode from df.\"\"\"\n",
    "    if 'df' not in globals() or df.empty:\n",
    "        return pd.DataFrame(), \"DB data not loaded. Please load the .db file first.\"\n",
    "    if 'datetime' not in df.columns:\n",
    "        return pd.DataFrame(), \"DB data has no 'datetime' column.\"\n",
    "\n",
    "    if range_mode_select.value == 'whole':\n",
    "        segment = df.copy()\n",
    "        msg = f\"Whole dataset | {segment['datetime'].min()} to {segment['datetime'].max()}\"\n",
    "        return segment, msg\n",
    "\n",
    "    # Time-window mode\n",
    "    start_raw = acc_start_input.value.strip()\n",
    "    end_raw = acc_end_input.value.strip()\n",
    "\n",
    "    if not start_raw or not end_raw:\n",
    "        return pd.DataFrame(), \"Please enter both start and end timestamps for the time window.\"\n",
    "\n",
    "    try:\n",
    "        start_dt = pd.to_datetime(start_raw)\n",
    "        end_dt = pd.to_datetime(end_raw)\n",
    "        # Assume user times are in Asia/Manila\n",
    "        if start_dt.tzinfo is None:\n",
    "            start_dt = start_dt.tz_localize('Asia/Manila')\n",
    "        else:\n",
    "            start_dt = start_dt.tz_convert('Asia/Manila')\n",
    "        if end_dt.tzinfo is None:\n",
    "            end_dt = end_dt.tz_localize('Asia/Manila')\n",
    "        else:\n",
    "            end_dt = end_dt.tz_convert('Asia/Manila')\n",
    "    except Exception as e:\n",
    "        return pd.DataFrame(), f\"Failed to parse start/end timestamps: {e}\"\n",
    "\n",
    "    mask = (df['datetime'] >= start_dt) & (df['datetime'] <= end_dt)\n",
    "    segment = df[mask].copy()\n",
    "    if segment.empty:\n",
    "        return pd.DataFrame(), \"No DB data in the selected time window.\"\n",
    "\n",
    "    msg = f\"Time window | {start_dt} to {end_dt} | rows: {len(segment)}\"\n",
    "    return segment, msg\n",
    "\n",
    "\n",
    "def _run_detection(segment):\n",
    "    \"\"\"Select detection pipeline based on stroke type.\n",
    "\n",
    "    Freestyle/Backstroke/Breaststroke -> identify_stroke_cycles (accel-based)\n",
    "    Butterfly -> detect_strokes_butterfly (gyro-based)\n",
    "    \"\"\"\n",
    "    stroke_type = stroke_type_select.value\n",
    "\n",
    "    if stroke_type == 'Butterfly':\n",
    "        stroke_count, peaks, signal = detect_strokes_butterfly(segment)\n",
    "        label = 'Smoothed gyro magnitude'\n",
    "    else:\n",
    "        stroke_count, peaks, signal = identify_stroke_cycles(segment)\n",
    "        label = 'Filtered accel signal (ay+az)'\n",
    "\n",
    "    return stroke_count, peaks, signal, label\n",
    "\n",
    "\n",
    "def on_evaluate_accuracy(_):\n",
    "    with eval_output:\n",
    "        clear_output()\n",
    "\n",
    "        if accuracy_source_select.value != 'db':\n",
    "            print(\"Only DB-based detection is supported in this widget.\")\n",
    "            return\n",
    "\n",
    "        segment, msg = _get_eval_segment()\n",
    "        if segment.empty:\n",
    "            print(msg)\n",
    "            return\n",
    "\n",
    "        print(f\"Evaluation segment: {msg}\")\n",
    "        print(f\"Selected stroke type: {stroke_type_select.value}\")\n",
    "\n",
    "        # Run selected detection pipeline\n",
    "        stroke_count, peaks, signal, signal_label = _run_detection(segment)\n",
    "        print(f\"\\nDetected Stroke Count (peak detection): {stroke_count}\")\n",
    "\n",
    "        # Duration and stroke rate\n",
    "        duration_seconds = (segment['datetime'].max() - segment['datetime'].min()).total_seconds()\n",
    "        stroke_rate = (stroke_count / duration_seconds) * 60 if duration_seconds > 0 else 0\n",
    "        print(f\"Estimated Stroke Rate: {stroke_rate:.2f} strokes/min\")\n",
    "\n",
    "        # Compare to user-provided actual stroke count\n",
    "        actual = actual_strokes_input.value\n",
    "        if actual > 0:\n",
    "            count_error = stroke_count - actual\n",
    "            abs_error = abs(count_error)\n",
    "            percent_error = (abs_error / actual) * 100.0\n",
    "            count_accuracy = max(0.0, 1.0 - (abs_error / actual)) * 100.0\n",
    "\n",
    "            print(\"\\nAccuracy vs. manual strokes:\")\n",
    "            print(f\"  Actual strokes: {actual}\")\n",
    "            print(f\"  Detected strokes: {stroke_count}\")\n",
    "            print(f\"  Count error (detected - actual): {count_error}\")\n",
    "            print(f\"  Absolute error: {abs_error}\")\n",
    "            print(f\"  Percent error: {percent_error:.2f}%\")\n",
    "            print(f\"  Count accuracy: {count_accuracy:.2f}%\")\n",
    "        else:\n",
    "            print(\"\\nActual stroke count not provided (or zero). Enter a positive number to see accuracy.\")\n",
    "\n",
    "        # Quick plot for tuning / visual inspection\n",
    "        try:\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.plot(segment['datetime'], signal, label=signal_label)\n",
    "            if len(peaks) > 0:\n",
    "                plt.plot(segment['datetime'].iloc[peaks], signal[peaks], 'rx', label='Detected strokes')\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Signal value')\n",
    "            plt.title('Stroke detection segment')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Plotting failed: {e}\")\n",
    "\n",
    "\n",
    "eval_button.on_click(on_evaluate_accuracy)\n",
    "\n",
    "# Display UI\n",
    "\n",
    "display(widgets.HTML(value=\"<h3>Stroke Count Accuracy Evaluation</h3>\"))\n",
    "display(accuracy_source_select)\n",
    "display(stroke_type_select)\n",
    "display(range_mode_select)\n",
    "\n",
    "range_box = widgets.VBox([acc_start_input, acc_end_input])\n",
    "\n",
    "\n",
    "def _on_range_mode_change(change):\n",
    "    if change['new'] == 'whole':\n",
    "        acc_start_input.layout.display = 'none'\n",
    "        acc_end_input.layout.display = 'none'\n",
    "    else:\n",
    "        acc_start_input.layout.display = ''\n",
    "        acc_end_input.layout.display = ''\n",
    "\n",
    "\n",
    "range_mode_select.observe(_on_range_mode_change, names='value')\n",
    "\n",
    "# Initialize visibility\n",
    "acc_start_input.layout.display = 'none'\n",
    "acc_end_input.layout.display = 'none'\n",
    "\n",
    "display(range_box)\n",
    "\n",
    "display(actual_strokes_input)\n",
    "display(eval_button, eval_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
